[TOC]

# 数据结构

zookeeper客户端框架 curator Apache的开源包

> 链表反转

* 头插法

```java
 // 从头开始插，所有节点重新插一遍
Node headInsert(Node head) {
    Node tmp = new Node(-1, null);
    Node node = head;
    while (node != null) {
        Node nextNode = node.next;
        node.next = tmp.next;
        tmp.next = node;
        node = nextNode;
    }
    return tmp.next;
}
```

* 就地反转法

```java
// 头结点不动，直接改变节点next的指向，即以头结点为圆点旋转
Node seftReverse(Node head) {
    Node tmp = new Node(-1, head);
    Node preNode = head;
    Node curNode = preNode.next;
    while (curNode != null) {
        preNode.next = curNode.next;
        curNode.next = tmp.next;
        tmp.next = curNode;
        curNode = preNode.next;
    }
    return tmp.next;
}
```

> 检测链表的循环

```java
// 弗洛伊德算法
boolean checkLoop(Node head) {
    Node slow = head;
    Node fast = head;
    while (slow != null && fast.next != null) {
        slow = slow.next;
        fast = fast.next.next;
        if (slow == fast) {
            return true;
        }
    }
    return false;
}
```

> 获得倒数第K个节点

```java
// 位差法
Node getInverseKNode(Node head, int k) {
    Node p1 = head;
    Node p2 = head;
    while (k > 0) {
        p2 = p2.next;
    }
    while(p2 != null) {
        p1 = p1.next;
        p2 = pe.next;
    }
    return p1;
}
```

> 删除链表中重复的节点

```java
Node delRepeactNode(Node head) {
    Node p1 = head;
    while (p1 != null) {
        Node p2 = p1.next;
        Node pre = p1;
        while (p2 != null) {
            // 删掉p2
            if (p2.data = p1.data) {
                pre.next = p2.next;
                p2 = pre.next;
            } else {
              	pre = p2;
                p2 = p2.next;
            }
        }
    }
    return head;
}
```

## 树

> 二叉树

* 可通过前序和中序或者后序和中序确定一棵二叉树
* 前序遍历：第一次遍历到即输出

```java
void preOrder(Node node) {
    print(node.data);
    preOrder(node.left);
    preOrder(node.right);
}
```

* 中序遍历：第二次遍历到即输出

```java
void midOrder(Node node) {
    midOrder(node.left);
    print(node.data);
    midOrder(node.right);
}
```

* 后序遍历：第三次遍历到即输出

```java
void postOrder(Node node) {
    postOrder(node.left);
    postOrder(node.right);
    print(node.data);
}
```

> 二叉查找树（二叉搜索树、二叉查找树）

* 左节点小于父节点，右节点大于父节点
* 通过中序遍历即可获得有序的数列

> 二叉平衡树

* 基于二叉查找树，所有节点左右子树高度最多相差一
* 插入节点失衡通过旋转方式恢复平衡，[参考地址](https://blog.csdn.net/qq_25940921/article/details/82183093)
* 左左（左节点l1的左节点l2插入n），以l1为原点右旋，l1的右节点作为原根节点的左节点
* 右右（右节点r1的右节点r2插入n），以r1为原点左旋，r1的左节点作为原根节点的右节点
* 左右（左节点l1的右节点r2插入n），以r2为原点左旋，再以r2为原点右旋
* 右左（右节点r1的左节点l2插入n），以l2为原点右旋，再以l2为原点左旋

> 红黑树  

* 节点为黑色或者红色
* 根节点为黑色节点
* 所有叶子节点为黑色（职位null）
* 红色节点的子节点为黑色节点
* 任意接到到每个叶子节点路劲中黑色节点的数量相同
* 新插入的节点是红色
* 插入时的调整规则

![image-20200831193140110](/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200831193140110.png)

## HashMap

* 默认容量(数组桶的长度capacity = 16)，默认扩容因子(factor = 0.75)，扩容阀值(threshold = capacity * factor)，扩容时到原来桶大小的两倍

* 每个数组元素存储链表或者红黑树的头指针，相同hash值按单链表或者红黑树存储

* 当链表长度>=7时，修改链表结构为红黑树

* 当红黑树元素小于7个时，修改红黑树结构为链表

* 由key的hashCode与hashCode高16位异或运算并与桶数组长度取余得到key所在桶的位置[hash & (n - 1)]即hash % n

  扰动函数，使低位更离散。

* 根据key找到元素在链表或者红黑树中的位置

* 为什么不一直用红黑树？ 

  ​		在理想状态下，受随机分布的hashCode影响，链表中的节点遵循泊松分布，而且根据统计，链表中节点数是8的概率已经接近千分之一，而且此时链表的性能已经很差了。所以在这种比较罕见和极端的情况下，才会把链表转变为红黑树。因为链表转换为红黑树也是需要消耗性能的，特殊情况特殊处理，为了挽回性能，权衡之下，才使用红黑树，提高性能。红黑树旋转消耗比较大。

## ArrayList

* 数组大小初始大小默认为10，容量不足时扩容到原来的容量的1.5倍，扩容不满足则扩容到存放下元素的最小长度

## CopyOnWriteArrayList

* 使用ReentrantLock（独占锁）

## ConcurrentHashMap

LinkedHashmap

​		双向链表

Treemap

​		红黑树

# 算法

> 冒泡排序

```java
void bubbleSort(int[] arr) {
    for (i in arr) {
        for (j = i + 1 in arr) {
            if (arr[j] < arr[i]) {
                swap(arr, i, j);
            }
        }
    }
}
```

> 选择排序

```java
void chooseSort(int[] arr) {
    for (i in arr) {
        min = i;
        for (j = i + 1 in arr) {
            if (arr[j] < arr[min]) {
                min = j
            }
        }
        if (i != min) {
            swap(arr, i, min);
        }
    }
}
```

> 快速排序

```java
// 分治法
void quickSort(int[] arr, int low, int high) {
    pivot = arr[low];
    l = low;
    h = high;
    while (arr[h] > pivot  && l < h) {
        h--;
    }
    if (l < h) {
        swap(arr, l, h);
        l++;
    }
    while (arr[l] < pivot && l < h) {
        l++;
    }
    if (l < h) {
        swap(arr, l, h);
        h--;
    }
    if (low < l) {
        sort(arr, low, l);
    }
    if (high > l) {
        sort(arr, l, high)
    } 
}
```

> 归并排序

```java
// 分治法
int[] mergeSort(int[] arr) {
    if (arr.length == 1) {
        return arr;
    }
    middle = arr.length / 2;
    int[] left = Arrays.copyOfRange(arr, 0, middle);
    int[] right = Arrays.copyOfRange(arr, middle, arr.length);
    merge(mergeSort(left), mergetSort(right));
}

int[] merge(int[] left, int[right] right) {
    arr[] result = int[left.length + right.length];
    int l = 0;
    int r = 0;
    int index = 0;
    while(l < left.length && r < right.length) {
        if (left[l] < right[r]) {
            result[index++] = left[l];
            l++;
        } else {
            result[index++] = right[r];
            r++;
        }
    }
    if (l < left.length) {
        while(l < left.length) {
            result[index++] = left[l++];
        }
    }
    if (r < right.length) {
        while(r < right.length) {
            result[index++] = right[r++];
        }
    }
    return result;
}
```

> 计数排序

```java
void countingSort(int[] arr) {
    min = min(arr)
    max = max(arr)
    int[] bucket = new int[max - min + 1];
    for (i in arr) {
        bucket[i - min]++;
    }
    int index = 0;
    for (i = 0; i < bucket.length; i++) {
        while (bucket[i] > 0) {
            result[index++] = i + min;
            bucket[i]--;
        }
    }
}
```

> 桶排序

```java
void sort(int[] arr, int bucketSize) {
    min = min(arr);
    max = max(arr);
    bucketCount = (max - min) / bucketSize + 1;
    int[][] buckets = new int[bucketCount][0];
    for (i = 0; i < arr.length; i++) {
       index = (arr[i] - min) / bucketSize;
       append(buckets[index], arr[i]);
    }
    // 对桶进行计数排序
    index = 0;
    for (i = 0; i < buckets.length; i++) {
        countSort(buckets[i]);
        for (j in buckets[i]) {
            arr[index++] = j;
        }
    }
}
```

> 基数排序

```java
// 按数值位数排序
void sort(int[] arr) {
    unitCount = getUnitCount(getMax(arr));
    scale = 10;
    mod = 10;
    dev = 1;
    for (i = 0; i < unitCount; i++) {
        int[][] bucket = new int[scale * 2][0];
        for (j in arr) {
            // unit + scale，负数0~9，正数10~20
            index = (j % mod) / dev + scale;
            append(bucket[index], j);
        }
        index = 0;
        for (i = 0; i < buckets.length; i++) {
            for (j = 0; j < buckets[i].length; j++) {
                arr[index++] = buckets[i][j];
            }
        }
    }
}
```

# 网络协议

## tcp

* 面向连接的可靠传输协议
* 建立连接三次握手
  ![tcp_connect](http://image.newleaf.top/tcp_connect.png)
* 释放连接四次分手
  ![tcp_disconnect](http://image.newleaf.top/tcp_disconnect.png)

滑动窗口

```
    窗口滑动协议是TCP使用的一种流量控制方法。该协议允许发送方在停止并等待接收确认报文前可以连续发送多个分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输。只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。收发两端的窗口按照以上规律不断地向前滑动，因此这种协议又称为滑动窗口协议。
```

​		分为发送窗口和接受窗口



拥塞控制

　　1.慢开始

> ​		最初的TCP在连接建立成功后会向网络中发送大量的数据包，这样很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。因此新建立的连接不能够一开始就大量发送数据包，而只能根据网络情况逐步增加每次发送的数据量，以避免上述现象的发生。具体来说，当新建连接时，cwnd初始化为1个最大报文段(MSS)大小，发送端开始按照拥塞窗口大小发送数据，每当有一个报文段被确认，cwnd就增加1个MSS大小。这样cwnd的值就随着网络往返时间(Round Trip Time,RTT)呈指数级增长，达到ssthresh后，进入拥塞避免状态。

　　2.拥塞避免

> ​	为了在发送端调节所要发送的数据量，定义了一个“拥塞窗口”（Congestion Window），在发送数据时，将拥塞窗口的大小与接收端ack的窗口大小做比较，取较小者作为发送数据量的上限。当网络阻塞时：
>
> 1.把ssthresh（慢启动门限）降低为cwnd值的一半
> 2.把cwnd重新设置为1
> 3.重新进入慢启动过程。
>
> 重新进入慢启动状态

　　3.快重传

​		发送端：当某一段报文丢失了，图中（1001-2000）数据段丢失了，接收方没有接收到该数据段，则会一直给发送端发送ACK（下一个是1001），如果发送端连续收到同样的ACK（下一个是1001），就会将对应的（1001-2000）重新发送，这时候如果接收端收到1001后，再次返回的就是ACK（7001）。这种机制被称为“高速重发机制”（快速重传）

<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200823124802172.png" alt="image-20200823124802172" style="zoom:40%;" />

​		接收端：接收端的下一个2001丢失了，但是发送端收到了ACK（下一个3001），说明1-3000的数据段已经接收到了，数据已经传输到了发送端，所以不需要理会。

<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200823124842776.png" alt="image-20200823124842776" style="zoom:40%;" />

　　4.快恢复

​			至少收到了3个Duplicated Acks，说明网络也不那么糟糕，可以快速恢复

Close_wait:	

​		表示被动关闭方等待关闭。当收到对方调用close函数发送的FIN报文时，回应对方ACK报文，此时进入CLOSE_WAIT状态。

	一个进程打开一个socket，然后此进程再派生子进程的时候，此socket的sockfd会被继承。socket是系统级的对象，现在的结果是，此socket被两个进程打开，此socket的引用计数会变成2。
	调用close(sockfd)时，内核检查此fd对应的socket上的引用计数。如果引用计数大于1，那么将这个引用计数减1，然后返回。如果引用计数等于1，那么内核会真正通过发FIN来关闭TCP连接。
	调用shutdown(sockfd，SHUT_RDWR)时,内核不会检查此fd对应的socket上的引用计数，直接通过发FIN来关闭TCP连接。
	
	 现在应该真相大白了，可能是服务器的实现有点问题，父进程打开了socket，然后用派生子进程来处理业务，父进程继续对网络请求进行监听，永远不会终止。客户端发FIN过来的时候，处理业务的子进程的read返回0，子进程发现对端已经关闭了，直接调用close()对本端进行关闭。实际上，仅仅使socket的引用计数减1，socket并没关闭。从而导致系统中又多了一个CLOSE_WAIT的socket。。
	
	如何避免这样的情况发生？
		shutdown(sockfd, SHUT_RDWR);
		close(sockfd);。

# jvm

## 垃圾回收器

### 	cms

​			cms会有浮动垃圾和内存碎片问题

​			concurrent mode failure（并发模式失效）：

​			promotion failed（新生代晋升失败）：默认老年代占用80%晋升回收，可减少比例。或者设置多少次fullgc后进行一次标记整理

### 	g1

​			每个区域可回收的对象大小不同，回收时，会进行移动并整理。减少内存碎片。有个特殊区域（Humongous 黑忙个四），用来存储大对象。默认超过区域50% 就当做大对象。

​			每个区域物理上不连续，逻辑连续，通过remember set记录指针。每个区域又被分成若干个card，通过cardtable记录card是否被修改过，避免整堆遍历。

#### 	 g1 怎么解决浮动垃圾（STAB）？

​			利用pre-write barrier，在并发标记阶段记录引用变化记录并保存在队列中，重新标记时会扫描这个队列进行标记。

#### 	collection set 

​			记录区域垃圾占比，达到一定比例后将region放入cs，等待回收。

#### 	write barrier

​			使用写屏障保证并发阶段引用关系变更导致的标记错误。A-> B -> C 标记时A标记完成标为黑色，B为灰色。此时用户线程将引用关系改为A->C，因为A已经标记为黑色，C为白色，引用存在但会被回收，导致空指针。写屏障在进行内存写操作前进行，会将C变成灰色。重新标记时继续遍历检查。

​			在指令前增加lock前缀（阻止这个信号会使总线锁定，阻止其他处理器接管总线访问内存），如果要访问的内容已经在cache里了。则会锁缓存，通过缓存一致性协议保证原子性。

​		

## jvm组成

* JVM主要由类加载模块、运行时数据区、执行器、内存回收等组成，可参见[一张图看懂jvm](https://www.cnblogs.com/bigben0123/p/9685474.html)
  ![jvm](http://image.newleaf.top/jvm.png)

![img](https://mmbiz.qpic.cn/mmbiz_jpg/l89kosVutokVL8r9J3zTicCRNSC2EXwW2qVeDoo1K6MptMZQib00C7MydayrPcNhonxArupYPey9PMZAYrdYm13g/640?wx_fmt=jpeg)



## 内存模型

* 主要包括线程共享（方法区、堆内存）、线程隔离（栈内存、程序计数器、本地方法区栈）
* 方法区存储Class定义信息（类信息、类变量、常量、方法定义、方法表、指向class实例的引用等）
* 栈内存中存放了每个线程的栈区，栈区内存放了线程的基本类型变量，复杂类型的引用(refrence)，执行环境上下文(入参等)，操作指令（执行哪个方法对应的指令）
* 堆内存存放了所有的对象（类的非静态变量随class实例一起存放在堆区）
* 在jdk7中堆内存分为年轻代（一个eden两个survivor区）、老年代、永久代（jvm虚拟内存中，jdk8开始移除用metaspace代替，在主内存(主机)中）
* 年轻代采用复制清除算法，将eden和一个survivor存活对象复制到另一个survivor，再清空eden和一个survivor，因为年轻代会清理很多对象，这样效率高（复制的量少）
* 老年代采用标记整理算法

## 类加载器

> jvm加载为双亲(父辈)委派加载模式

* 当加载一个类时，如果当前加载器有parents，则先交给parents进行加载，没有parents则交给顶层BootstrapClassLoader加载，都没加载到则自己加载
* 保证被加载类的唯一性
* 默认jvm有三级类加载器
* ApplicationClassLoader：加载类路径的类
* ExtensionClassLoader：加载{JAVA_HOME}/jre/ext/lib的类
* BootstampClassLoader：加载{JAVA_HOME}/lib的类

## 类的加载过程

> 可分为加载、连接（验证、准备、解析）、初始化几个过程

* 加载：将class文件加载到内存中，生成这个类的Class对象
* 验证：验证class文件是否符合规范
* 准备：为类变量(静态)变量分配内存空间，并赋予默认值
* 解析：将符号引用变为直接引用(将符号引用修改为内存指针或者地址，比如将常量)
* 初始化：为类变量赋予程序猿设置的值，只有当触发new，getstatic，putstatic，invokestatic这4条指令或者通过reflect调用类时才会进行初始化，注意是static不是final static，main方法属于invokestatic

## 对象的的初始化(类初始化 + 对象初始化)

* 如果类没有被加载则先加载该类，如果类的父类没有加载则先加载父类
* 执行父类中的静态代码（静态变量、代码块，顺序按照代码顺序），类初始化阶段
* 执行子类中的静态代码（静态变量、代码块，顺序按照代码顺序），类初始化阶段
* 在堆内存分配对象内存空间
* 将Class中方法区属性的定义拷贝一份到堆内存，为对象赋予默认值
* 执行父类非静态代码块
* 执行子类非静态代码块
* 执行父类构造方法
* 执行子类构造方法
* 如果有引用，则在栈内存中创建对象的引用变量赋予对象的地址值

## 对象布局

* 包括对象头：MarkWord、Length（数组对象才有）、Class(Object)Point，对象数据InstanceData
* MarkWord包含了Identify hashCode、锁信息、GC信息三部分
  ![MarkWord](http://image.newleaf.top/markword.png)

## JVM参数

>  -Xss:每个线程的栈大小
>  -Xms:初始堆大小，默认物理内存的1/64
>  -Xmx:最大堆大小，默认物理内存的1/4
>  -Xmn:新生代大小
>  -XX:NewSize:设置新生代初始大小
>  -XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。
>  -XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。
>  -XX:MetaspaceSize:设置元空间大小
>  -XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。
>  垃圾回收统计信息
>  -XX:+PrintGC
>  -XX:+PrintGCDetails
>  -XX:+PrintGCTimeStamps 
>  -Xloggc:filename
>  收集器设置
>  -XX:+UseSerialGC:设置串行收集器
>  -XX:+UseParallelGC:设置并行收集器
>  -XX:+UseParallelOldGC:老年代使用并行回收收集器
>  -XX:+UseParNewGC:在新生代使用并行收集器
>  -XX:+UseParalledlOldGC:设置并行老年代收集器
>  -XX:+UseConcMarkSweepGC:设置CMS并发收集器
>  -XX:+UseG1GC:设置G1收集器
>  -XX:ParallelGCThreads:设置用于垃圾回收的线程数
>  并行收集器设置
>  -XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。
>  -XX:MaxGCPauseMillis:设置并行收集最大暂停时间
>  -XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)
>  CMS收集器设置
>  -XX:+UseConcMarkSweepGC:设置CMS并发收集器
>  -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。
>  -XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。
>  -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩
>  -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收
>  -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收
>  -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况
>  -XX:ParallelCMSThreads:设定CMS的线程数量
>  -XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发
>  -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理	
>  G1收集器设置 
>  -XX:+UseG1GC:使用G1收集器
>  -XX:ParallelGCThreads:指定GC工作的线程数量
>  -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区
>  -XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集
>  -XX:MaxGCPauseMillis:目标暂停时间(默认200ms)
>  -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%)
>  -XX:G1MaxNewSizePercent:新生代内存最大空间
>  -XX:TargetSurvivorRatio:Survivor填充容量(默认50%)
>  -XX:MaxTenuringThreshold:最大任期阈值(默认15)
>  -XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集
>  -XX:G1HeapWastePercent:堆废物百分比(默认5%)
>  -XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8)

## 逃逸分析

### 		什么是逃逸分析

> ​		逃逸分析，是一种可以有效减少Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。 逃逸分析（Escape Analysis）算是目前Java虚拟机中比较前沿的优化技术了。

### 		什么时候会发生逃逸？

> 方法逃逸(对象逃出当前方法)：
>  当一个对象在方法里面被定义后，它可能被外部方法所引用，例如作为调用参数传递到其它方法中。
> 线程逃逸((对象逃出当前线程)：
>  这个对象甚至可能被其它线程访问到，例如赋值给类变量或可以在其它线程中访问的实例变量

### 		相关JVM参数

>     -XX:+DoEscapeAnalysis 开启逃逸分析
>     -XX:+PrintEscapeAnalysis 开启逃逸分析后，可通过此参数查看分析结果。
>     -XX:+EliminateAllocations 开启标量替换
>     -XX:+EliminateLocks 开启同步消除
>     -XX:+PrintEliminateAllocations 开启标量替换后，查看标量替换情况。

### 		逃逸分析的好处

>      （1）栈上分配。
>                 在一般应用中，不会逃逸的局部对象占比很大，如果使用栈上分配，那大量对象会随着方法结束而自动销毁，垃圾回收系统压力就小很多。
>      （2）同步消除
>                 线程同步本身比较耗时，如果确定一个变量不会逃逸出线程，无法被其它线程访问到，那这个变量的读写就不会存在竞争，对这个变量的同步措施可以清除。
>
>      ```
>      //消除前
>      public void f() {
>          Object hollis = new Object();
>          synchronized(hollis) {
>              System.out.println(hollis);
>          }
>      }
>      //消除后
>      public void f() {
>          Object hollis = new Object();
>          System.out.println(hollis);
>      }
>      ```
>
>      （3）标量替换。
>                 1）标量就是不可分割的量，java中基本数据类型，reference类型都是标量。相对的一个数据可以继续分解，它就是聚合量（aggregate）。
>                 2）如果把一个对象拆散，将其成员变量恢复到基本类型来访问就叫做标量替换。
>                 3）如果逃逸分析证明一个对象不会被外部访问，并且这个对象可以被拆散的话，那么程序真正执行的时候将可能不创建这个对象，而改为直接在栈上创建若干个成员变量。
>
>      ```
>      //前
>      private static void alloc() {
>         Point point = new Point（1,2）;
>         System.out.println("point.x="+point.x+"; point.y="+point.y);
>      }
>      //后
>      private static void alloc() {
>         int x = 1;
>         int y = 2;
>         System.out.println("point.x="+x+"; point.y="+y);
>      }
>      ```
>
>      

# 多线程

## volatile

* volatile关键字能防止指令重排
* 能保证线程的可见性，线程修改完volatile关键字修饰变量后（线程工作内存中），会立即刷新到主内存，其他主线程嗅探到总线的数据变更到自己工作内存中用到该变量时，会使自己工作内存中的地址失效，而去读取主内存
* 由于线程修改工作线程和刷新主内存并不是原子的，并且多线程调度具有随机性，所以当t1、t2都读取了变量i，而t1在修改完i之后没来得及刷新主内存，cpu开始调度t2就会出现线程不安全的情况

## 锁的升级过程(syncronized)

偏向锁->自旋锁(CAS)->重量级锁
![锁的升级过程](http://image.newleaf.top/lock_grade.png)
![锁的比较](http://image.newleaf.top/lock_compare.png)

## CAS(compare and swap)

底层由cpu的cpmxchg指令实现，lock if cmpxchg (compare and exchage)

* 修改前会拿预期值(原值)与主内存中的值进行比较，相同则修改，不同则取主内存当前值继续循环
* 会有ABA问题，compareAndSet可以使用AtomicStampedReference参数解决

## AQS(abstract queue syncronized)

* 锁等待队列（FIFO,锁池），双向链表，队头为状态节点，获得锁的线程置于队头下一个节点，新增抢锁线程置于队尾
* 独占锁，头结点释放锁后（线程节点通知状态state=1，并剔除调），唤醒队列中下一个节点的线程，每个线程节点查看前一个节点通知状态state=0，是则抢锁，不是则等待
* 共享锁，头结点释放锁后（通知状态state=0），从头节点开始一个一个链式的唤醒后续线程节点继续工作
* 条件队列 condition

## Syncronized和ReentrantLock应用场景

- Synchronized是非公平的，lock公平和非公开可选，非公平吞吐量比公平大。
- 独占锁和共享锁
- 读写锁
- 悲观锁（写多）、乐观锁（读多）

## 锁粗化、锁消除

​		粗化：方法中多个锁，合成一个。

​		锁消除：执行的方法已经加锁，调这个方法的代码不会有线程安全问题。

## 读写锁

获取读锁

- 操作1：读写需要互斥，因此当存在写锁并且持有写锁的线程不是该线程时获取失败。
- 操作2：是否存在等待写锁的线程，存在的话则获取读锁需要等待，避免写锁饥饿。(非公平下写锁优先级是比较高的)
- 操作3：CAS获取读锁，实际上是state字段的高16位自增。
- 操作4：获取成功后再ThreadLocal中记录当前线程获取读锁的次数。



## 线程的五种状态

* new、runnable、running、blocked、dead
* sleep、join(底层调用wait)、wait会使线程进入blocked状态，wait会释放对象锁、sleep不会

## 线程池

* corePoolSize，核心线程数量，当新的任务提交时，如果线程池还没有达到corePoolSize则创建新的线程

* maxPoolSize，最大线程数量，当新的任务提交时，如果等待对象已满，则继续创建新的线程，直到达到maxPoolSize

* timeUnit和keepAliveTime：非核心线程创建出的线程最大空闲时间

* blockingQueue：corePool满时，新任务等待队列。ArrayBlockingQueue，有界队列，使用该类型队列maxPoolSize才会生效;LinkedBlockingQueue，无界队列，使用该类型队列maxPoolSize失效

* threadFactory，线程工厂，可对线程进行加工（如设置线程名称，方便出问题时排查）

* rejectedPolicy：线程池满时的任务拒绝策略，java提供了AbortPolicy（抛出异常）,DiscardPolicy（直接抛弃）,CallerPolicy（在threadPool调用线程执行）,DiscardOldestPolicy（移除最老的任务）

  

  ### 几种线程池

* scheduledThreadpool使用DelayedWorkQueue，coreSize,Integer.maxValue

* newFixedThreadPool、newSingle使用LinkedBlockingQueue

* newCacheThreadPool使用SynchronousQueue,0.Integer.maxValue

  ​		SynchronousQueue没有容量，是无缓冲等待队列，是一个不存储元素的阻塞队列，会直接将任务交给消费者，必须等队列中的添加元素被消费后才能继续添加新的元素。拥有公平（tansforQueue）和非公平(tansforStack)策略.使用SynchronousQueue阻塞队列一般要求maximumPoolSizes为无界，避免线程拒绝执行操作。
  
  
  
  ## 怎么选择合理的线程数
  
  - 对于CPU密集型任务，一般选择CPU核数+1（多一个为了保证其他线程因异常原因导致暂停时CPU不会中断任务）。
  
  - 对于IO密集型任务来说，IO操作不是所有线程都调度，需要更大的池，估算任务等待的时间和执行时间占比。选择两倍CPU或4倍CPU操作。也要考虑是否依赖其他链接，如数据库等，避免依赖链接有限制。
  
  - 实际情况：
  
    ​		假设要求一个系统的TPS（Transaction Per Second或者Task Per Second）至少为20，然后假设每个Transaction由一个线程完成，继续假设平均每个线程处理一个Transaction的时间为4s。那么问题转化为：
    如何设计线程池大小，使得可以在1s内处理完20个Transaction？
    计算过程很简单，每个线程的处理能力为0.25TPS，那么要达到20TPS，显然需要20/0.25=80个线程。
  
    **IO密集型** 一般情况下，如果存在IO，那么肯定W/C > 1（阻塞耗时一般都是计算耗时的很多倍），但是需要考虑系统内存有限（每开启一个线程都需要内存空间），这里需要在服务器上测试具体多少个线程数适合（CPU占比、线程数、总耗时、内存消耗）。如果不想去测试，保守点取1即可，Nthreads = Ncpu x (1 + 1) = 2Ncpu。这样设置一般都OK。
    **CPU密集型** 假设没有等待W = 0，则W/C = 0。Nthreads = Ncpu。
  
  
    Redis6.0基本都是内存操作，这种情况下单线程可以很高效地利用CPU。而多线程适用场景一般是：存在相当比例的IO和网络操作。Redis 的瓶颈并不在 CPU，而在内存和网络，所以高版本redis支持多线程也是只多线程处理IO读写操作。<img src="https://img-blog.csdnimg.cn/2020050520583331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phNW9u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;" />

## ThreadLocal

* ThreadLocal不存储数据，只是作为Thread.localMaps存储数据的key，之所以能做到线程数据隔离，是因为线程之间的隔离性
* 每个Thread中维护了一个ThraeadLocal.LocalMaps的引用
* 调用ThreadLocal.set(value)时会以当前ThreadLocal对象为key在当前线程的LocalMaps中设置一个Entry<threadLocal,value>
* ThreadLocal.get()则是获取当前线程LocalMaps中以该threadLocal对象为key的值

## 奇怪的知识

​		sleep(0)的作用？

​				Thread.Sleep(0)的作用，就是“触发操作系统立刻重新进行一次CPU竞争”。竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权。

# 设计模式

# tomcat

engine(servlet容器)->host（虚拟主机）->context(web应用)->wrap(servlet实例)->servlet

Tomcat中最顶层的容器是Server，代表着整个服务器，从上图中可以看出，一个Server可以包含至少一个Service，用于具体提供服务。

Service主要包含两个部分：Connector（连接器）和Container（容器）。从上图中可以看出 Tomcat 的心脏就是这两个组件，他们的作用如下：

> 1、Connector用于处理连接相关的事情，并提供Socket与Request和Response相关的转化;
> 2、Container用于封装和管理Servlet，以及具体处理Request请求；

<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200824175435374.png" alt="image-20200824175435374" style="zoom:50%;" />

 一个Server包括多个Service，一个Service可以包含多个Connector和一个Container，这样Connector在获得客户端的socket之后，交给对应的Service，由Service来找到对应的Container，进而处理客户端的相关请求。

Engine是一个完整的Servlet容器，其下面拥有多个虚拟主机，它的责任就是将用户请求分配给一个虚拟上机处理。接口Engine代表一个Servlet引擎，其实现类是StandardEngine，先来看看构造方法

Host组件包含两个主要的Valve，一个Valve决定请求由哪一个Context处理，另一个Valve负责处理在Context中未被捕获的异常。

# mysql

### 	索引优化

​			最左匹配原则

​			回表

​			索引下推

​			覆盖索引

​		

> 索引 

* 可使用explain命令查看查询计划是否命中索引，例如`explain select * from t where name = xx`
* mysql索引使用B+Tree结构存储，和BTree的区别是，B+Tree只在叶子节点存放数据f非叶子节点存放指针和键值，并为叶子节点接引入了单向链表连接（便于范围查询）
* innodb是聚簇索引，即数据和索引存放在一起，主键索引叶子节点直接存放数据，非主键索引叶子节点存放主键(innodb必须要有主键，没有默认生成)
* myisam是非聚簇索引，主键索引和非主键索引叶子节点都存放数据在磁盘的地址（myisam可以没有主键，主键索引和非主键索引差别不大）

> 读缓存  
>
> * 采用LRU队列+分代+年龄（计时）策略  
> * 分代可以避免预读失效问题(根据局部相关性原理，mysql按页加载数据，即避免加载了数据使用不到而占据着最优缓存)  
> * 老年代增加年龄计时，数据初始只加入老年代队列头部，只有在老年代存留一段时间并再次访问到时加入到年轻代头部，年轻代缓存会挤入老年代（防止扫表时大量无关数据占据缓存）
>   写缓存
> * 思路为随机写->顺序写，单写->批量写  

* log_buf->os_cache->disk

> 双写缓存(double write buffer)
>
> * 主要解决mysql页(16k)和操作系统数据块(4k)大小不一致，解决对系统写4个块数据发生异常导致数据不一致的问题（某些块失败）  

* 流程即变为log_buf->dwb_mem->dwb_disk->data_disk

* binlog、redolog和undolog

  ​	binlog（都有）

  ​		记录变更的sql更新删除等，用户复制。 三种格式。STATEMENT（sql）、ROW（变化后的行数据）、MIXED（混合）

  ​	redolog（innodb）

  ​		记录磁盘上物理的变化 redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)

  ​	undolog

  ​		用户回滚和mvvc

  * 主从复制

  ​	通过master同步binlog到salver 的relaylog salver起一个工作线程同步，relay log相当于缓冲区

  并行复制

  ​		一个工作线程可能性能不够导致堆积，主从延迟大。 5.7版本增加并行复制策略，通过多个work线程处理relaylog。

  ​	策略：

  ​		不能造成更新覆盖，同一行的更新必须被分发到同一个Worker 中；

  ​		同一个事务不能被拆开，必须被分配到同一个Worker 中。

  ​	

  ​	每个 Worker 都对应一个 hash 表，用于保存当前 Worker 执行的 binlog 涉及的表。hash 表的 key 是 “库名+表名”，value 表示 Worker 中有多少个事务操作这个表。

  

  5.7.22 版本里面，新增了基于 writeset 的并行复制

  ​		对于事务更新的每一行，都计算出一个 hash 值，组成集合 writeset。如果两个事务的 writeset 没有交集，说明事务没有操作相同的行，事务之间是可以并行的；

  ​		writeset 是在主库上面生成后直接写到 binlog 里面的，这样在备库执行时，就需要解析 binlog 的内容，节省了很多计算量；

  

* B+树的叶子节点存的是什么？

  主键索引存的是完整记录，索引的key是数据表的主键，辅助索引存的是主键的值

  <img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200903214954651.png" alt="image-20200903214954651" style="zoom:50%;" />

* 索引下推

  ​		在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。
  索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。

* 索引合并 

  并集 （or）、交集（and）、先取交集再合并

* 覆盖索引

  只查联合索引中的一部分（最左匹配），会利用联合索引查 如index(name,age,sex)  只查name 则无需回表。

select 快照读

当执行select操作是innodb默认会执行快照读，会记录下这次select后的结果，之后select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前select的数据，这就实现了可重复读了。快照的生成当在第一次执行select的时候，也就是说假设当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据。之后无论再有其他事务commit都没有关系，因为快照已经生成了，后面的select都是根据快照来的。

当前读

对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。**在执行这几个操作时会读取最新的版本号记录，写操作后把版本号改为了当前事务的版本号，所以即使是别的事务提交的数据也可以查询到**。假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。也正是因为这样所以才导致幻读。

- 在快照读读情况下，mysql通过mvcc来避免幻读。
- 在当前读读情况下，mysql通过next-key来避免幻读

* 事务隔离级别

  ​	读未提交

  ​	读已提交 （行锁解决脏读）

  ​	可重复读 （mvvc + 行锁解决不可重复读）

  ​	串行化

  ​			读共享锁、写独占锁 只有一个事务可以写。

  

  ### RR、RC生成时机

  - `RC`隔离级别下，是每个`快照读`都会`生成并获取最新`的`Read View`；
  - 而在`RR`隔离级别下，则是`同一个事务中`的`第一个快照读`才会创建`Read View`, `之后的`快照读获取的都是`同一个Read View`，之后的查询就`不会重复生成`了，所以一个事务的查询结果每次`都是一样的`。

  **RC 与 RR 在锁方面的区别**

  ​	1 显然 RR 支持 gap lock(next-key lock)，而RC则没有gap lock。因为MySQL的RR需要gap lock来解决幻读问题。而RC隔离级别则是允许存在不可重复读和幻读的。所以RC的并发一般要好于RR；

  ​	2 RC 隔离级别，通过 where 条件过滤之后，不符合条件的记录上的行锁，会释放掉(虽然这里破坏了“两阶段加锁原则”)；但是RR隔离级别，即使不符合where条件的记录，也不会释放行锁和gap lock；所以从锁方面来看，RC的并发应该要好于RR；另外 insert into t select ... from s where 语句在s表上的锁也是不一样的，参见下面的例子2；

* 幻读

  ​	快照读：通过mvvc

  ​	当前读：行锁+间隙锁

  可重复读

  ![image-20200823172605633](/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200823172605633.png)

  ![img](https://img-blog.csdnimg.cn/20190515143938256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nhbnl1ZXNhbjAwMDA=,size_16,color_FFFFFF,t_70)

**自定义规则分表**

大表可以按照业务的规则来分解为多个子表。通常为以下几种类型，也可自己定义规则。

```
1 Range（范围）–这种模式允许将数据划分不同范围。例如可以将一个表通过年份划分成若干个分区。
2 Hash（哈希）–这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。例如可以建立一个对表主键进行分区的表。
3 Key（键值）-上面Hash模式的一种延伸，这里的Hash Key是MySQL系统产生的。
4 List（预定义列表）–这种模式允许系统通过预定义的列表的值来对数据进行分割。
5 composite（复合模式） –以上模式的组合使用
```

## 分库分表

​		分页查询

​				禁止跳页查询：从第一页开始，每个表去前N条，内存排序后取N条后记录max值，第二页再根据max值取N条

​				二次查询：

​					1、query改写  limit (pageNum*pageSize)/n,pageSize ，然后排序

​					2、取N个结果的最小值

​					3、二次改写，改为between语句，范围为第二部的最小值加上每个库的最大值，查询。

​					4、通过二次查询的结果，知道minid的全局offset，然后通过跳过offset-globaloffset 在取pageSize个就是最终数据

​				改写后排序：

​					1、limit 10，10，改写为limit 0，20，每个表返回后再排序。

## [MyISAM和InnoDB的区别](http://www.cnblogs.com/zhangchaoyang/articles/4214237.html)

1. MySQL默认采用的是MyISAM。
2. MyISAM不支持事务，而InnoDB支持。InnoDB的AUTOCOMMIT默认是打开的，即每条SQL语句会默认被封装成一个事务，自动提交，这样会影响速度，所以最好是把多条SQL语句显示放在begin和commit之间，组成一个事务去提交。
3. InnoDB支持数据行锁定，MyISAM不支持行锁定，只支持锁定整个表。即 MyISAM同一个表上的读锁和写锁是互斥的，MyISAM并发读写时如果等待队列中既有读请求又有写请求，默认写请求的优先级高，即使读请求先到，所以 MyISAM不适合于有大量查询和修改并存的情况，那样查询进程会长时间阻塞。因为MyISAM是锁表，所以某项读操作比较耗时会使其他写进程饿死。
4. InnoDB支持外键，MyISAM不支持。
5. InnoDB的主键范围更大，最大是MyISAM的2倍。
6. InnoDB不支持全文索引，而MyISAM支持。全文索引是指对char、 varchar和text中的每个词（停用词除外）建立倒排序索引。MyISAM的全文索引其实没啥用，因为它不支持中文分词，必须由使用者分词后加入空 格再写到数据表里，而且少于4个汉字的词会和停用词一样被忽略掉。
7. MyISAM支持GIS数据，InnoDB不支持。即MyISAM支持以下空间数据对象：Point,Line,Polygon,Surface等。
8. 没有where的count(*)使用MyISAM要比InnoDB快得多。因 为MyISAM内置了一个计数器，count(*)时它直接从计数器中读，而InnoDB必须扫描全表。所以在InnoDB上执行count(*)时一般 要伴随where，且where中要包含主键以外的索引列。为什么这里特别强调“主键以外”？因为InnoDB中primary index是和raw data存放在一起的，而secondary index则是单独存放，然后有个指针指向primary key。所以只是count(*)的话使用secondary index扫描更快，而primary key则主要在扫描索引同时要返回raw data时的作用较大。

## 细节

​	datatime和timestamp有什么不同？时间戳范围为1970-2038年。 dataime8字节 timestamp4字节

# redis

## 存储结构

​	redisDb.id 存储着 redis 数据库以整数表示的号码。redisDb.dict 存储着该库所有的键值对数据。redisDb.expires 保存着每一个键的过期时间。

## 底层数据结构

* 六种数据结构：SDS（简单动态字符串）、LIST（双向链表）、SKIPLIST（跳表）、DICT（hash表）、INTSET（整数集合）、ZIPLIST（压缩列表）
* 参见[redis底层数据结构](https://www.cnblogs.com/ysocean/p/9080942.html#_label0)  
* 参见[redis的五大数据类型实现原理](https://www.cnblogs.com/ysocean/p/9080942.html#_label0)

![redis-encoding](http://image.newleaf.top/redis-encoding.png)



## HyperLogLog

> ​	  基数（cardinality）就是一个集合中不同元素的个数。计数存在一定的误差，误差率整体较低。标准误差为 0.81% 。
>
> <img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200903231809787.png" alt="image-20200903231809787" style="zoom:50%;" />
>
> 优化：前几位bit进行分桶，
>
> 使用调和平均数计算平均值（偏向小的值。）
>
> 回到Redis，对于一个输入的字符串，首先得到64位的hash值，用前14位来定位桶的位置（共有214，即16384个桶）。后面50位即为伯努利过程，每个桶有6bit，记录第一次出现1的位置count，如果count>oldcount，就用count替换oldcount。



## 过期策略

> 分为主动过期和被动过期
>
> * 主动过期即key过期后，当有客户端访问到该key时会被清除
> * 被动删除，就是redis   10次/每秒测试随机20个key的过期状态，过期则删除，过期比率>25%时继续重复执行检测删除

## 备份持久化方式

* 默认使用rdb(快照)方式，该方式定时将数据序列化后进行持久化，优点是数据恢复快
* aof（写日志）方式，log_buf->os_cache->disk

> 三种同步方式
>
> * 每次写日志并flush os buffer 每次执行多了一次IO，效率低
> * 每秒flush  os buffer，默认方式，redis挂掉会丢失一秒数据
> * 等os cache 满了自动flush挂掉会丢失数据

* 低版本两种方式互斥，高版本可支持两种方式共同使用，aof只附加rdb快照时间之后的日志，优点是提升恢复速度和保证保证完整性

* AOF如果过大可以配置重写策略，将一些命令合并。使用rewirte机制，rewrite机制现在达到一定的条件redis会自动触发
  其具体的流程就是：
  1，redis主进程clone一个子进程
  2，子进程根据当前内存的数据，构建一个新的日志，写入一个新的AOF文件中
  3,   在重写的过程中，由于redis还会有新的写入，为了避免数据丢失，会开辟一块内存用于存放重写期间产生的写入操作，等到重写完毕后会将这块内存中的操作再追加到aof文件中。

  4，当子进程完成了任务，redis就会把新的日志文件追加到新的AOF文件中
  5，使用新的AOF文件替换旧的AOF文件

  在redis.conf中，可以配置rewrite策略
  auto-aof-rewrite-percentage 100
  auto-aof-rewrite-min-size 64mb
  解释：比如说上一次AOF rewrite之后，是128mb
  然后就会接着128mb继续写AOF的日志，如果发现增长的比例，超过了之前的100%，256mb，就可能会去触发一次rewrite
  但是此时还要去跟min-size，64mb去比较，256mb > 64mb，才会去触发rewrite

  如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损
  用redis-check-aof --fix命令来修复破损的AOF文件

## 内存满淘汰策略(maxmemory可在redis.conf配置)

* 进行取样-lru淘汰，有五种模式（单线程模式一次淘汰大量key会造成长时间等待）
* noeviction：不淘汰，有新的内存需求返回错误码
* allkeys-lru（最常用）：尝试回收最久最少使用的key
* volatile-lru：尝试回收过期集合内最久最少使用的key
* allkeys-random：随机回收key
* volatile-random：随机回收过期集合内的key
* volatile-ttl：回收过期时间较近的key

## sentinel

> 哨兵模式即redis-server以--sentinel模式运行状态，sentinel主要有四个职责

* 监控：可以配置监视集群中的master，并监视master所属replica(slave)的运行状态
* 提醒：当监视到节点发生故障时可以通知管理员或者其他应用程序(提供了api)
* 自动故障迁移：当master发生故障时，自动选择新的master，并将(发通知指令)故障master的replica从新指向新的master
* 提供配置：为客户端提供当前集群中可用master的地址

> 自动故障迁移的过程

* 当配置应答超时时间内master未给出正常应答时，哨兵会将本地master状态置为主观离线，
* 哨兵会发送指令询问其他哨兵，当达到配置个数哨兵置为主管离线时，哨兵将master置为客观离线状态
* 哨兵通过(纪元周期进行)选举进行故障迁移的节点(配置最新)进行故障迁移
* 选举成功后，寻找数据最多的replica为新的master，数据都相同则选择pid最小的节点
* 通知老master的replica指向新的master，并在指向完成后通知其他sentinel更新配置
* 从备选node中，按照如下顺序选择新的master
  1、较低的slave_priority（这个是在配置文件中指定，默认配置为100）
  2、较大的replication offset（每个slave在与master同步后offset自动增加）
  3、较小的runid（每个redis实例，都会有一个runid,通常是一个40位的随机字符串,在redis启动时设置，重复概率非常小）
  4、如果以上条件都不足以区别出唯一的节点，则会看哪个slave节点处理之前master发送的command多，就选谁。

## 缓存穿透、击穿、雪崩

> 缓存穿透

* 指数据不存在，使得请求都落到了数据库
* 可通过设置缓存默认值来解决，或者通过BloomFilter来过滤

> 缓存击穿
>
> * 指缓存失效了没有被redis主动删除，大并 	发时大量请求落到数据库上

* 可设置多级缓存，底层失效时间高于高层
* 预热缓热，后台定时加载或者请求发现快到期重新加载
* 对刷新缓存操作加锁，再进行缓存加载操作

```java
if (setnx(mutexKey) == 1) {
    val = db.find(key);
    cache.set(key, val);
} else {
    sleep(5);
    val = cache.get(key);
}
```

> 缓存雪崩

* 指大量缓存在同一时间失效，倒是大量请求落到数据库
* 可为缓存加上一个随机过期时间
* 也可通过多级缓存解决

# mongodb

## 	mongo的ObjectId组成是什么？

​			时间戳(秒)+机器号+进程ID+计数器

## 	mongo为什么使用b-树

​			作为非关系型的数据库，MongoDB 对于遍历数据的需求没有关系型数据库那么强，它追求的是读写单个记录的性能；虽然遍历数据的查询是相对常见的，但是 MongoDB 认为查询单个数据记录远比遍历数据更加常见，由于 B 树的非叶结点也可以存储数据，所以**查询一条数据所需要的平均随机 IO 次数会比 B+ 树少**，使用 B 树的 MongoDB 在类似场景中的查询速度就会比 MySQL 快。这里并不是说 MongoDB 并不能对数据进行遍历，我们在 MongoDB 中也可以使用范围来查询一批满足对应条件的记录，只是需要的时间会比 MySQL 长一些。

​		既然 MongoDB 认为查询单个数据记录远比遍历数据的查询更加常见，那为什么不使用哈希作为底层的数据结构呢？如果我们使用哈希，那么对于所有单条记录查询的复杂度都会是 `O(1)`，但是遍历数据的复杂度就是 `O(n)`；如果使用 B+ 树，那么单条记录查询的复杂度是 `O(log n)`，遍历数据的复杂度就是 `O(log n) + X`，这两种不同的数据结构一种提供了最好的单记录查询性能，一种提供了最好的遍历数据的性能，但是这都不能满足 MongoDB 面对的场景 —— 单记录查询非常常见，但是对于遍历数据也需要有相对较好的性能支持，哈希这种性能表现较为极端的数据结构往往只能在简单、极端的场景下使用。

## 	mongo主从

​				通过oplog进行数据同步，类似binlog

## 	mongo副本集

​		<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200827215842351.png" alt="image-20200827215842351" style="zoom:50%;" />

## 	mongodb选举

​			raft协议

## 	mongodb分片

​			类似分表，启动一个mongos进程用来路由，设置合理的片键进行拆分。

## 为什么选择mongodb

> 不确定业务模型，快速验证的原型项目。
> 高写负载的场景，存储评论，日志等大规模的非核心业务数据。
> 大规模或可能爆发式增长的非结构化数据存储。

# 消息队列

## rabbitmq

### 		rebbitmq组成

> Broker：通俗讲就是server，接收客户端连接，实现AMQP协议的消息队列和路由功能的进程；
> Virtual Host：虚拟主机，类似于权限控制组。一个Virtual Host里可以有若干的Exchange和Queue，但权限控制的最小粒度是Virtual Host；
> Producer：消息生产者；
> Consumer：消息消费者；
> Queue：存储消息的队列容器；
> Message：生产者和消费者需要的消息数据；
> Connection：一个tcp连接；
> Channel：一个管道连接，是tcp连接内的连接(broker),使用现有的TCP连接进行数据传输；
> Exchange：交换机，消息路由，生产者发送的消息并不是直接发送到队列中而是先到指定的路由中，然后由路由根据路由key绑定的队列发送到指定队列中；
> Binding：建立路由和队列容器的绑定关系；
> Routing key：路由key，主要用于寻找队列。

### 		Exchange的几种工作模式

> 1. Direct--路由模式
>
>    任何发送到Direct Exchange的消息都会被转发到RouteKey指定的Queue。
>    这种模式下不需要将Exchange进行任何绑定(binding)操作。
>    消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字。
>    如果vhost中不存在RouteKey中指定的队列名，则该消息会被抛弃。
>
> 2. Fanout--发布/订阅模式
>    任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有Queue上。
>    这种模式不需要RouteKey。
>    这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个Queue，一个Queue可以同多个Exchange进行绑定。
>    如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。
>
> 3. Topic--匹配订阅模式
>    任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的Queue上。
>    就是每个队列都有其关心的主题，所有的消息都带有一个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的队列。
>    这种模式需要RouteKey，也许要提前绑定Exchange与Queue。
>    在进行绑定时，要提供一个该队列关心的主题。
>    .“#”表示0个或若干个关键字，“*”表示一个关键字。
>    同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息

### 		RabbitMQ工作模式

> 在 RabbitMQ 官网上提供了 6 中工作模式：简单模式、工作队列模式、发布/订阅模式、路由模式、主题模式 和 RPC 模式。
>
> ##### 简单模式和工作队列模式
>
> 这两种模式非常简单，只涉及生产者、队列、消费者。
> 生产者负责生产消息，将消息发送到队列中，消费者监听队列，队列有消息就进行消费。
> 工作队列模式其实就是有多个消费者的简单模式。
> 当有多个消费者时，消费者平均消费队列中的消息。
>
> ##### 发布/订阅、路由与主题模式
>
> 这三种模式就要用到Exchange了。
> 生产者不直接与队列交互，而是将消息发送到交换机中，再由交换机将消息发送到已绑定改交换机的队列中给消费者消费。
> 常用的交换机类型有 3 种：fanout、direct、topic。
>
> fanout不处理路由键，很像子网广播，每台子网内的主机都获得了一份复制的消息。
> 发布/订阅模式就是指使用fanout交换模式。fanout 类型交换机转发消息是最快的。
>
> direct模式处理路由键，需要路由键匹配才能转发。
> 路由模式使用的是 direct 类型的交换机。
>
> topic：将路由键和某模式进行匹配。
> 主题模式使用的是 topic 类型的交换机。
>
> ##### RPC 模式
>
> 客户端发送一个请求消息然后服务器回复一个响应消息。为了收到一个响应，我们需要发送一个'回调'的请求的队列地址。

## kafka

> 如何保证系统的稳定性

* 采取主从模式，每个partion在follower中存储副本

* 可配置每次消息follower同步成功leader的个数，当leader挂掉时，可由这些follower中选取新的leader

## rebalance

	触发 Rebalance 的时机
		1、消费组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。
		2、订阅的 Topic 个数发生变化。
		3、订阅 Topic 的分区数发生变化。
	算法：
		partition-Id(__consumer_offsets) = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)2
		
	优化：
			1、通过延迟进入PreparingRebalance状态减少reblance次数，等待一段时间(group.initial.rebalance.delay.ms)让其他consumer到来后再一起执行reblance，从而降低其频率。
			2、静态成员ID，使得consumer重新加入时，可以保持旧的标识，这样Kafka就知道之前挂掉的consumer又恢复了，从而不需要Reblance。


​	

### 为什么这么快？

​		partion顺序写入

	收到消息后 Kafka 会把数据插入到文件末尾
	如果不删除硬盘肯定会被撑满，所以 Kakfa 提供了两种策略来删除数据：
		基于时间
		基于 Partition 文件大小		

​		使用io多路复用技术 epoll

​		写入使用mmap

```
Kafka 提供了一个参数 producer.type 来控制是不是主动 Flush：
如果 Kafka 写入到 mmap 之后就立即 Flush，然后再返回 Producer 叫同步 (Sync)。
如果 Kafka 写入 mmap 之后立即返回 Producer 不调用 Flush 叫异步 (Async)。
```

​		读取使用sendfile

​		Kafka 把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候 Kafka 直接把文件发送给消费者，配合 mmap 作为文件读写方式，直接把它传给 Sendfile。

### 存储结构

​			topic只是逻辑概念，不涉及到存储，partition才是物理概念。在Kafka文件存储中，同一个topic下有多个不同的partition，每个partiton为一个目录，partition的名称规则为:topic名称+有序序号

​			partition是一个文件夹，其中包含多个segment，segment由一对文件组成，一个索引文件后缀.index，一个数据文件后缀.log

​			segment文件命名规则

​		上一个segment在partition中的最大offset数值，即，比如00000000000000345678.log文件中的第一条消息的offset为345679最大为64位的long，不足位数补0，如00000000000000345678.log

​		索引文件内容

​				[offset，物理偏移地址及log文件里的位置]  二分查找

​		数据文件

​			存储一系列message:

- offset 偏移量，消息的唯一标识，通过offset能找到唯一消息，类型long 8bytes

- MessageSize 消息长度，类型int32 4bytes

- crc32校验码， 4bytes，校验message

- magic， 表示本次发布kafka服务程序协议版本号 1byte

- attributes 独立版本，标识压缩类型，编码类型 1byte

- key length 4bytes 当key length=-1时，key字段可不写

- key 可选

- payload 实际消息内容

  

  ### 怎么保证消息不丢失

> 多线程消费丢失消息
> 	即开启了位移自动提交，多线程处理的时候，如果有一个线程出现问题，但是还是提交了位移，会发生消息丢失。
> 	怎么破？ 关闭自动提交位移，消费者端配置参数：enable.auto.commit=false
>
> 发送方消息丢失
>
> ​	解决策略：
>
> ​		1.异步方式缓冲区满了，就阻塞在那，等着缓冲区可用，不能清空缓冲区
>
> ​		2.发送消息之后回调函数，发送成功就发送下一条，发送失败就记在日志中，等着定时脚本来扫描
>
> ​		3.同步模式的时候，确认机制设置为-1，也就是让消息写入leader和所有的副本。
>
> ![file](https://img2020.cnblogs.com/other/268922/202004/268922-20200427001333633-991943074.jpg)

### 存储结构设计原因

- 为什么有segment，而不是把partition直接设计成单个文件？

  - 方便消费后删除，可以节约空间，如果是单个文件，该文件由于会被不断写入，无法删除，则会无限增加。当需要清理时，则需要在保证写入的同时，清理该文件的前面已经过期的消息，效率十分低下。

- 为什么有partition？

  - 方便水平扩展broker，如果不设计多个partition，那么当部署完成之时，topic就会被限定在一台机器上了，随着业务增加，最终会陷入瓶颈

- 索引文件的作用

  - 使查找效率为O(1)，即与文件大小无关，与查找的位置无关

### kafka写入流程

	1.producer 先从 zookeeper 的 "/brokers/.../state" 节点找到该 partition 的 leader
	2.producer 将消息发送给该 leader
	3.leader 将消息写入本地 log
	4.followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK
	5.leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK

### Kafka和mq的区别

​		RabbitMQ比Kafka可靠，kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用。RabbitMQ支持事务。

# spring

# rpc





# 分布式事务

​		1、2PC(二阶段提交)

​				一阶段 询问 二阶段提交

​		2、3PC（三阶段提交）

​				一 询问 二 预提交（锁资源） 三 提交

​		3、TCC

​		如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面的处理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让应用自己定义数据操作的粒度，使得降低锁冲突、提高吞吐量成为可能。TCC的不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。

​		4、最大努力型事务

# 本地事务表

​		db操作与事务表操作在一个事务中，操作完成后进行后面的操作，成功后删除事务表中的记录。如果失败则有其他补偿任务进行补偿。

# 分布式一致性协议

​		1、es是怎么选举的？

​				每个参与选举的节点获取符合选举条件的节点集合，对nodeid进行排序，选择第一个进行投票。如果获得超过半数节点且自己给自己也投票，那当前节点则选举成功。

​		2、zk 

​				三种状态：leading、looking（选举中或刚启动时）、following

​			zad协议

​				原则：

​				1、ZAB 协议确保那些已经在 Leader 提交的事务最终会被所有服务器提交。

​				2、ZAB 协议确保丢弃那些只在 Leader 提出/复制，但没有提交的事务

​				协议分为消息广播和崩溃恢复

​				消息广播：（二阶段提交）leader将请求转为一个proposal（提案），同时给提案分配一个自增的zxid（64位数字，高32位代表任期id，低32位代表提案id），通过fifo的队列进行广播，当有超过半数follower返回ack后，再想所有follower comment提交。

​				崩溃恢复：

​					选举：每个节点向其他节点发起投票请求（sid和zxid），同时也接受其他节点发送的投票请求进行对比，依次对比zxid和sid，如果其他节点比自己的大，则修改投票。如果有节点收到超过半数投票，则成为准leader，继续进入数据恢复阶段。否则清空投票，进入下一轮选举（任期）。

​					数据恢复：准leader同步最新的任期id和leader最新的提案，follower同步或回退。超过半数同步完成，则正式成为leader，进入消息广播模式。

​		3、kafka选举

​			broker 选举：

​				通过zk进行选举，监听到与zk断开连接或退出后，其他broker去zk注册/controller 注册成功的则为leader

​			分区选举：

​				isr中顺序取第一个	

## paxos协议

**一、两个操作：**

1. Proposal Value：提议的值；
2. Proposal Number：提议编号，可理解为提议版本号，要求不能冲突；

**二、三个角色：**

1. Proposer：提议发起者。Proposer 可以有多个，Proposer 提出议案（value）。所谓 value，可以是任何操作，比如“设置某个变量的值为value”。不同的 Proposer 可以提出不同的 value，例如某个Proposer 提议“将变量 X 设置为 1”，另一个 Proposer 提议“将变量 X 设置为 2”，但对同一轮 Paxos过程，最多只有一个 value 被批准。
2. Acceptor：提议接受者；Acceptor 有 N 个，Proposer 提出的 value 必须获得超过半数(N/2+1)的 Acceptor批准后才能通过。Acceptor 之间完全对等独立。
3. Learner：提议学习者。上面提到只要超过半数accpetor通过即可获得通过，那么learner角色的目的就是把通过的确定性取值同步给其他未确定的Acceptor。

**三、协议过程**

**协议分为两大阶段，每个阶段又分为A/B两小步骤：**

1. 准备阶段（占坑阶段）
   1. 第一阶段A：Proposer选择一个提议编号n，向所有的Acceptor广播Prepare（n）请求。
   2. 第一阶段B：Acceptor接收到Prepare（n）请求，若提议编号n比之前接收的Prepare请求都要大，则承诺将不会接收提议编号比n小的提议，并且带上之前Accept的提议中编号小于n的最大的提议，否则不予理会。
2. 接受阶段（提交阶段）
   1. 第二阶段A：整个协议最为关键的点：Proposer得到了Acceptor响应
      1. 如果未超过半数accpetor响应，直接转为提议失败；
      2. 如果超过多数Acceptor的承诺，又分为不同情况：
         1. 如果所有Acceptor都未接收过值（都为null），那么向所有的Acceptor发起自己的值和提议编号n，记住，一定是所有Acceptor都没接受过值；
         2. 如果有部分Acceptor接收过值，那么从所有接受过的值中**选择对应的提议编号最大的**作为提议的值，提议编号仍然为n。但此时Proposer就不能提议自己的值，只能信任Acceptor通过的值，维护一但获得确定性取值就不能更改原则；
   2. 第二阶段B：Acceptor接收到提议后，如果该提议版本号不等于自身保存记录的版本号（第一阶段记录的），不接受该请求，相等则写入本地。

raft和paxos协议区别

​		

# zookeeper

​		节点类型：

			PERSISTENT                持久化节点
			PERSISTENT_SEQUENTIAL     顺序自动编号持久化节点，这种节点会根据当前已存在的节点数自动加 1
			EPHEMERAL                 临时节点， 客户端session超时这类节点就会被自动删除
			EPHEMERAL_SEQUENTIAL      临时自动编号节点

​		为什么zk是CP的？

​			进行leader选举时集群都是不可用。

​			不能保证每次服务请求的可用性。

# Elasticsearch

一、ES 写数据的底层原理 

>    \1. 在到达primary shard的时候 ，数据先写入内存buffer ， 此时，在buffer里的数据是不会被搜索到的同时生成一个translog日志文件 ， 将数据写入translog里
>
>    \2. 如果内存buffer空间快满了，就会将数据refresh到一个新的segment file文件中，而且es里每隔1s就会将buffer里的数据写入到一个新的segment file中，这个segment file就存储最最近1s中buffer写入的数据，如果buffer里面没有数据，就不会执行refresh操作，当建立segment file文件的时候，就同时建立好了倒排索引库。
>
>    \3. 在buffer refresh到segment之前 ，会先进入到一个叫os cache中，只要被执行了refresh操作，就代表这个数据可以被搜索到了。数据被输入os cache中，buffer就会被清空了，所以为什么叫es是准实时的？NRT，near real-time，准实时。默认是每隔1秒refresh一次的，所以es是准实时的，因为写入的数据1秒之后才能被看到。还可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。也可以通过配置文件 index.refresh_interval 修改refresh时间，增大写入吞吐量。
>
>    \4. 就这样新的数据不断进入buffer和translog，不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。随着这个过程推进，translog会变得越来越大。当translog达到一定长度的时候，就会触发commit操作。translog也是先进入os cache中，然后每隔5s持久化到translog到磁盘中，
>
>    \5. commit操作，第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer 每隔30分钟flush
>
>    \6. es也有可能会数据丢失 ，有5s的数据停留在buffer、translog os cache, segment file os cache中，有5s的数据不在磁盘上，如果此时宕机，这5s的数据就会丢失，如果项目要求比较高，不能丢失数据，就可以设置参数，每次写入一条数据写入buffer，同时写入translog磁盘文件中，但这样做会使es的性能降低。
>
>    \7. 如果是删除操作，commit操作的时候就会生成一个.del文件，将这个document标识为deleted状态，在搜索结果召回还会有当前数据，只是通过del文件进行过滤。
>
>    \8. 如果是更新操作，就是将原来的document标识为deleted状态，然后新写入一条数据
>
>    \9. buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，当多到一定程度的时候，es就会自动触发merge(合并)造作，将所有segment file文件 merge成一个segment file，并同时物理删除掉标识为deleted的doc。
>
>    10.写入性能优化 https://blog.csdn.net/zhuzhuba008/article/details/77483199/

二、ES节点类型

  混合节点

  master节点

​		主资格节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。

  data节点

​		主要对文档进行增删改查操作，聚合操作等。数据节点对cpu，内存，io要求较高

  clinet节点

​		处理路由请求，处理搜索，分发索引操作等，可以理解为负责负载均衡

  ingest节点（预处理节点）

 coordinate node

​		接收到request和response

三、脑裂问题

  配置最小选举节点数 大于n/2+1

​	当master节点宕机后，写入操作会被拒绝。基于最后已知的集群信息，读操作可以进行。

四、主分片和副分片的一致性

>   one：只要有一个活跃就可以
>
>   all：所有分片都活跃
>
>   默认：大于（主+副）/2 +1

五、segment结构

Stored Fields （存储字段）：

> ​		当我们想要查找包含某个特定标题内容的文件时，Inverted Index就不能很好的解决这个问题，所以Lucene提供了另外一种数据结构Stored Fields来解决这个问题。本质上，Stored Fields是一个简单的键值对key-value。默认情况下，ElasticSearch会存储整个文件的JSON source。

![img](http://5b0988e595225.cdn.sohucs.com/images/20190111/b635d5c807cf49ea8ca5a98c25afc455.jpeg)

Document Values ：为了排序、聚合（没有它对搜索结果做排序或者聚合操作，需要将倒排索引里的数据进行解析，然后进行一次倒排。 这个过程非常耗费时间）

Inverted Index（倒排索引：单词到文档id的关系） ：

> ​	单词词典：所有文档的单词以及单词到倒排列表的关联关系。  B+树和哈希拉链法。
>
> ​	倒排列表：记录了单词对应文档的结合。倒排列表是由**倒排索引项（Posting）** 组成，倒排索引项包含：
>
> - 文档 ID：用于获取原始信息
> - 词频（TF，Term Frequency）：该单词在文档中出现的次数，用于相关性评分
> - 位置（Position）：单词在文档中分词的位置，用于语句搜索（Phrase Query）
> - 偏移（Offset）：记录单词的开始结束位置，实现高亮显示（比如用 GitHub 搜索的时候，搜索的关键词会高亮显示）
>
> 一个倒排索引是由单词词典（Term Dictionary）和倒排列表（Posting List）组成的，单词词典会记录倒排列表中每个单词的偏移位置。比如当搜索 Allen 的时候，首先会通过单词词典快速定位到 Allen，然后从 Allen 这里拿到在倒排列表中的偏移，快速定位到在倒排列表中的位置，从而真正拿到倒排索引项 [12,15]（这里只是列了下 Document ID，其实是像上面讲的包含 4 项信息的项），拿到这个项可以去索引上拿到原始信息，可以去计算打分排序返回给用户。
>
> 内存中存的是单词索引(Term index)通过找到单词字典中共同前缀的位置，然后进行线性扫描找到对应的单词及倒排列表的指针  

![img](https://app.yinxiang.com/FileSharing.action?hash=1/b98861671940a2e9e5b017da93692861-87945)



数据写入过程：

![img](https://app.yinxiang.com/FileSharing.action?hash=1/2f5a7b2f4c8a079893d2a51906f28227-275507)

> 1.首先客户端根据配置的连接节点，通过轮询方式连接到一个coordinate节点。
> coordinate节点不是跟master/client/data节点一个维度的描述，它就是指处理客户端请求的节点。这个描述和cassandra的coordinate节点是一个概念。集群中所有的节点都可以是coordinate节点。
> 2.coodinate节点通过hash算法计算出数据在shard1上shard = hash(document_id) % (num_of_primary_shards)，然后根据节点上维护的shard信息，将请求发送到node1上。
> 3.node1 对索引数据进行校验，然后写入到shard中。具体细节见下一节写入到shard。
> 4.主节点数据写入成功后，将数据并行发送到副本集节点Node2,Node3。
> 5.Node2,Node3写入数据成功后，发送ack信号给shard1主节点Node1。
> 6.Node1发送ack给coordinate node
> 7.coordinate node发送ack给客户端。

shard写入：

> 1.数据写入到内存buffer。
> 2.同时写入到数据到translog buffer。
> 3.每隔1s数据从buffer中refresh到FileSystemCache中，生成segment文件，一旦生成segment文件，就能通过索引查询到了。
> 4.refresh完，memory buffer就清空了。
> 5.每隔5s中，translog 从buffer flush到磁盘中。
> 6.定期/定量从FileSystemCache中，结合translog内容flush index到磁盘中。做增量flush的。

query流程

> **1、query and fetch**
>
> 向索引的所有分片（shard）都发出查询请求，各分片返回的时候把元素文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去shard查询一次。但是各个shard返回的结果的数量之和可能是用户要求的size的n倍。
>
> **2、query then fetch**（默认的搜索方式）
>
> 如果你搜索时，没有指定搜索方式，就是使用的这种搜索方式。这种搜索方式，大概分两个步骤，第一步，先向所有的shard发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档document)，然后按照各分片返回的分数进行重新排序和排名，取前size个文档。然后进行第二步，去相关的shard取document。这种方式返回的document与用户要求的size是相等的。
>
> **3、DFS query and fetch**
>
> 这种方式比第一种方式多了一个初始化散发(initial scatter)步骤，有这一步，据说可以更精确控制搜索打分和排名。
>
> 4、**DFS** **query then fetch**
>
> 比第2种方式多了一个初始化散发(initial scatter)步骤。
>
> 初始化散发其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。

ES和solr的区别

> 当实时建立索引的时候，solr会产生io阻塞，而es则不会，es查询性能要高于solr。
> 在不断动态添加数据的时候，solr的检索效率会变的低下，而es则没有什么变化。
> Solr利用zookeeper进行分布式管理，而es自身带有分布式系统管理功能。Solr一般都要部署到web服务器上，比如tomcat。启动tomcat的时候需要配置tomcat与solr的关联。【Solr 的本质 是一个动态web项目】
> Solr支持更多的格式数据[xml,json,csv等]，而es仅支持json文件格式。
> Solr是传统搜索应用的有力解决方案，但是es更适用于新兴的实时搜索应用。
> a)单纯的对已有数据进行检索的时候，solr效率更好，高于es。
> Solr官网提供的功能更多，而es本身更注重于核心功能，高级功能多有第三方插件

ES内存中有什么

> 1. segment memory
>
>    fst 前缀索引
>
> 2. filter cache
>
>    Filter cache是用来缓存使用过的filter的结果集的，需要注意的是这个缓存也是常驻heap，无法GC的。默认的10% heap
>
> 3. field data cache
>
>    对搜索结果做排序或者聚合操作，需要将倒排索引里的数据进行解析，然后进行一次倒排。
>
> 4. bulk queue
>
>    当所有的bulk thread都在忙，无法响应新的bulk request的时候，将request在内存里排列起来，然后慢慢清掉。
>
> 5. indexing buffer
>
>    Indexing Buffer是用来缓存新数据，当其满了或者refresh/flush interval到了，就会以segment file的形式写入到磁盘。
>
> 6. cluster state buffer
>
>    ES被设计成每个node都可以响应用户的api请求，因此每个node的内存里都包含有一份集群状态的拷贝。这个cluster state包含诸如集群有多少个node，多少个index，每个index的mapping是什么？有少shard，每个shard的分配情况等等 (ES有各类stats api获取这类数据)。 
>
> 7. 超大搜索聚合结果集的fetch
>
>    ES是分布式搜索引擎，搜索和聚合计算除了在各个data node并行计算以外，还需要将结果返回给汇总节点进行汇总和排序后再返回。无论是搜索，还是聚合，如果返回结果的size设置过大，都会给heap造成很大的压力，特别是数据汇聚节点。超大的size多数情况下都是用户用例不对，比如本来是想计算cardinality，却用了terms aggregation + size:0这样的方式; 对大结果集做深度分页；一次性拉取全量数据等等。

基于乐观锁的并发控制

<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200826212740112.png" alt="image-20200826212740112" style="zoom:80%;" />

# 服务拆分原则

	单一职责，高内聚低耦合
	服务粒度适中
	以业务模型切入
	演进式的开发

# 系统设计原则

```
Single Responsibility Principle：单一职责原则
Open Closed Principle：开闭原则
Liskov Substitution Principle：里氏替换原则
Law of Demeter：迪米特法则
Interface Segregation Principle：接口隔离原则
Dependence Inversion Principle：依赖倒置原则
```



# 服务治理

​		熔断降级

​								



# 零拷贝

## 	mmap

> 它的工作原理是直接利用操作系统的 Page cache 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。通过 mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存）
>
> 在使用mmap调用时，系统并不是马上为其分配内存空间，而仅仅是添加一个VMA（虚拟内存空间）到该进程中，当程序访问到目标空间时，产生缺页中断。在缺页中断中，从pagecaches中查找要访问的文件块，若未命中，则启动磁盘I/O从磁盘中加载到pagecaches。然后将文件块在pagecaches中的物理页映射到进程mmap地址空间。
>
> 当程序退出或关闭文件时，系统是否会马上清除page caches中的相应页面呢？答案是否定的。由于该文件可能被其他进程访问，或该进程一段时间后会重新访问，因此，在物理内存足够的情况下，系统总是将其保持在page caches中，这样可以提高系统的整体性能(提高page caches的命中率，尽量少的访问磁盘)。只有当系统物理内存不足时，内核才会主动清理page caches。
>
> 当进程调用write修改文件时，由于page cache的存在，修改并不是马上更新到磁盘，而只是暂时更新到page caches中，同时标记目标page为dirty，当内核主动释放pagecaches时，才将更新写入磁盘(主动调用sync时，也会更新到磁盘)。<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200827100955469.png" alt="image-20200827100955469" style="zoom:50%;" />
>
> 一、什么是缺页中断？
>
> 进程线性地址空间里的页面不必常驻内存，在执行一条指令时，如果发现他要访问的页没有在内存中（即存在位为0），那么停止该指令的执行，并产生一个页不存在的异常，对应的故障处理程序可通过从外存加载该页的方法来排除故障，之后，原先引起的异常的指令就可以继续执行，而不再产生异常。

## 	sendfile

> 传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下：
>
> - 调用 Read 函数，文件数据被 Copy 到内核缓冲区。
> - Read 函数返回，文件数据从内核缓冲区 Copy 到用户缓冲区
> - Write 函数调用，将文件数据从用户缓冲区 Copy 到内核与 Socket 相关的缓冲区。
> - 数据从 Socket 缓冲区 Copy 到相关协议引擎。
>
>  以上细节是传统 Read/Write 方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次 Copy 操作：
>
> **硬盘—>内核 buf—>用户 buf—>Socket 相关缓冲区—>协议引擎**
>
> 而 Sendfile 系统调用则提供了一种减少以上多次 Copy，提升文件传输性能的方法。
>
> 运行流程如下：
>
> - Sendfile 系统调用，文件数据被 Copy 至内核缓冲区。
> - 再从内核缓冲区 Copy 至内核中 Socket 相关的缓冲区。
> - 最后再 Socket 相关的缓冲区 Copy 到协议引擎。



## IO多路复用

### 	

## 	epoll的两种触发方式

​	epoll监控多个文件描述符的I/O事件。epoll支持边缘触发(edge trigger，ET)或水平触发（level trigger，LT)，通过epoll_wait等待I/O事件，如果当前没有可用的事件则阻塞调用线程。

select和poll只支持LT工作模式，epoll的默认的工作模式是LT模式。

1. 水平触发的时机

   对于读操作，只要缓冲内容不为空，LT模式返回读就绪。
   对于写操作，只要缓冲区还不满，LT模式会返回写就绪。
   当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。

2. 边缘触发的时机

   - 对于读操作
     - 当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。
     - 当有新数据到达时，即缓冲区中的待读数据变多的时候。
     - 当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLIN事件时。
   - 对于写操作
     - 当缓冲区由不可写变为可写时。
     - 当有旧数据被发送走，即缓冲区中的内容变少的时候。
     - 当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD 修改EPOLLOUT事件时。
     - 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。

在ET模式下， 缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。

## 	epoll为啥高效

- select和poll的动作基本一致，只是poll采用链表来进行文件描述符的存储，而select采用fd标注位来存放，所以select会受到最大连接数的限制，而poll不会。

- select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。

- select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。

  epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符

- 不用重复传递事件集合

- epoll初始化时，内核开辟了epoll缓冲区，缓冲区内事件以epitem结点挂载到红黑树上，通过epoll_ctl的任何操作都是O(logN)

- epoll_wait调用仅需观察rdlist是否为空，若非空则拷贝rdlist到用户空间并返回触发事件数量，无需遍历

- 向内核中断处理注册回调，一旦关心的事件触发，回调自动将socket对应的epitem添加到rdlist中



## 系统负载过高怎么办

​		ps 查看cpu占用最多的进程，然后再通过ps H -eo pid,ppid,tid,time,%cpu --sort=%cpu -p 1229 查看cpu使用率高的线程id，将线程id转成16进制，通过jstack 打印线程堆栈 ，查看当前线程堆栈信息。



## 企业字典业务整理

​		12台机器（8核12G  负载 20）

​			fullgc 一天四次 每次180ms左右，younggc 一次30ms

​		

​		每天9点持续到晚上6点，高峰期QPS 1.2W，

​        帖子变更消息qps （3000+ ），为保证消息不丢失，通过redis队列异步消费，同时使用zset去重。起一个线程去拉取redis中延迟消费的帖子id，使用ratelimiter，应对突发流量。

​		搜索QPS（wcs 1800 ，es qps不到 500）

​		Wtable 

​				qps  2W  企业字典table qps  6K		平均耗时 0.5 ms

**WTable需要rowKey和colKey两个参数才能唯一的确认一条数据**。	

​		技术选型：

​			wcs：不支持单字段更新，业务逻s辑负担较重。业务需要嵌套字段。

​		    es可用性，每日增量重建，以及每日快照备份功能（es备份索引+当日增量hive）。





# RPC

![image-20200901141601456](/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200901141601456.png)



## 动态代理

​		cglib和jdk动态代理

jdk动态代理 实现InvocationHandler 通过Proxy.newProxyInstance 获取代理对象。

​		只能代理接口

cglib代理 实现 MethodInterceptor  通过Enhancer.create 获取代理对象

​		CGLIB是`针对类实现代理，主要是对指定的类生成一个子类`，重写其中的方法（`继承`），然后通过MethodIntercept.intercept方法来实现在调用父类方法的前后执行拦截。

​		CGLib`不能对声明为final的方法进行代理`，因为CGLib原理是动态生成被代理类的子类



## Double array trie （中文前缀树）

Double-array结合了array查询效率高、list节省空间的优点，具体是通过两个数组`base`、`check`来实现。Trie树可以等同于一个[自动机](http://www.cnblogs.com/en-heng/p/5247903.html)，状态为树节点的编号，边为字符；那么goto函数𝑔(𝑟,𝑐)=𝑠g(r,c)=s则表示状态r可以按字符c转移到状态s。base数组便是goto函数array实现，check数组为验证转移的有效性；两个数组满足如下**转移方程**：

base可以理解为hash地址

```
base[r] + c = s   base['前缀'] + index['后缀'] = index["前缀+后缀"]
check[s] = r      check['前缀+后缀'] = base['前缀']
```

<img src="/Users/lixiaowei/Library/Application Support/typora-user-images/image-20200903222917880.png" alt="image-20200903222917880" style="zoom:50%;" />

# 场景题

​		**题目：我有40亿个整数，再给一个新的整数，我需要判断新的整数是否在40亿个整数中，你会怎么做？**

> bitmap定义
> 	位图是一个数组的每一个数据的每一个二进制位表示一个数据，0表示数据不存在，1表示数据存在。
> 例如存储136这个数：
> 	确定136在整个数据的那个区间，136/32 = 4，即在第四个区间；
> 	确定136在这个区间的第几位（bit），136%32 = 25，即在第四区间的第25位上；
> 	将这个位置置为1，表示存在这个数。
>
> 布隆过滤器
>
> map reduce

### 什么时候会用户态到内核态切换

```
	1、系统调用
			80H中断机制
	2、 异常
			mmap缺页中断
	3、硬件设备的中断
```



## 线程上下文切换

	切换时机：
	    当前执行任务的时间片用完之后，系统CPU正常调度下一个任务；
	    当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务；
	    多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务；
	    用户代码挂起当前任务，让出CPU时间；
	    硬件中断；
	切换代价：
			程序计数器
			对共享变量的修改写回主存。
	怎么减少：
			减少线程
			乐观锁替代悲观锁


## 流量扩大十倍百倍怎么处理？

```
1、缓存，对于一致性不高的接口可以加本地缓存，读多写少的场景，数据库上层也要加缓存，也可以开启数据库缓存。
2、考虑看下代码实现中有没有循环调用的片段，有的话能不能考虑批量请求。是不是考虑看下代码实现中有没有可以并行的逻辑，考虑多线程处理。
3、业务上可不可以异步结构，非核心流程和核心流程拆解出来
4、数据预热，限流（信号量，令牌桶，队列），考虑瞬间峰值
```
